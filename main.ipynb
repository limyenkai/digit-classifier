{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7078663.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 6704061.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2256640.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 10444368.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size = 100,\n",
    "                        shuffle = True,\n",
    "                        num_workers = 1),\n",
    "\n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size = 100,\n",
    "                       shuffle = True,\n",
    "                       num_workers = 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1660f01d0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x16610cb90>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()               # zero out gradient\n",
    "        output = model(data)                # current state prediction\n",
    "        loss = loss_fn(output, target)      # calculate loss\n",
    "        loss.backward()                     # back propagate\n",
    "        optimizer.step()                    # do optimization step\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Acuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9j/p045mwns5lb5bvtrs9y0wsmr0000gn/T/ipykernel_86641/3258896293.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.301087\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.287134\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.168145\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.000355\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.871526\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.823664\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.788606\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.700025\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.723778\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.722751\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.651446\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.694723\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.646409\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.681827\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.646635\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.632847\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.639745\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.696465\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.675544\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.619191\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.618278\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.630680\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.617680\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.597166\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.561379\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.580350\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.582813\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.578901\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.630547\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.590959\n",
      "\n",
      "Test set: Average loss: 0.0153, Acuracy 9379/10000 (94%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.624883\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.603407\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.601750\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.586020\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.620211\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.580505\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.608950\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.568101\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.572609\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.617747\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.573018\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.573691\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.608578\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.579959\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.589054\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.592730\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.540798\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.584643\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.528436\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.535359\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.552668\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.559925\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.598386\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.562496\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.527819\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.540542\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.536721\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.593834\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.557937\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.524832\n",
      "\n",
      "Test set: Average loss: 0.0151, Acuracy 9557/10000 (96%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.609219\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.559002\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.528324\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.563183\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.543012\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.549993\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.541033\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.508502\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.550240\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.544798\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.580708\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.578305\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.579271\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.580147\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.518521\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.527641\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.533747\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.530695\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.540882\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.511885\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.522463\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.556346\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.571037\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.533347\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.532314\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.557141\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.543001\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.579063\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.505229\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.551547\n",
      "\n",
      "Test set: Average loss: 0.0150, Acuracy 9629/10000 (96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.584427\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.579570\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.543640\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.520316\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.516851\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.533305\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.553930\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.542979\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.547021\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.532860\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.525223\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.561734\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.540589\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.511070\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.570563\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.534082\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.553839\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.542432\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.520936\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.521213\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.513147\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.555950\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.518895\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.515213\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.538033\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.549804\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.517349\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.546812\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.533289\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.532428\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9672/10000 (97%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.538049\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.508981\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.587367\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.527862\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.581837\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.567913\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.526515\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.558047\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.523955\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.526613\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.562989\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.512316\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.525186\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.545211\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.524134\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.555249\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.535048\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.546987\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.518558\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.510814\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.524380\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.547265\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.540036\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.514846\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.531699\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.567185\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.542046\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.523650\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.545478\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.522070\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9673/10000 (97%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.534729\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.546823\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.557966\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.500877\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.518891\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.584752\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.505307\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.511762\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.502026\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.520033\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.514646\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.551422\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.537215\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.534064\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.559545\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.550769\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.512275\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.534163\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.547111\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.551602\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.505943\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.532101\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.534760\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.518488\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.572487\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.521598\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.544860\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.522941\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.565732\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.514235\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9702/10000 (97%\n",
      ")\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.537631\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.512252\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.522133\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.511333\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.516626\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.551610\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.521746\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.528271\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.495685\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.514843\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.532107\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.554955\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.526051\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.524054\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.525615\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.530117\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.513605\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.557679\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.521285\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.524814\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.545267\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.519663\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.535793\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.513683\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.517424\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.522839\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.514410\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.475193\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.534791\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.524571\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9718/10000 (97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.508228\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.520643\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.505616\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.524334\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.554775\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.487142\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.523490\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.493321\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.545631\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.493823\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.538962\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.504566\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.541851\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.516159\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.514438\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.517812\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.544411\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.540689\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.494567\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.497457\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.525789\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.516061\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.507494\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.526588\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.534414\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.509026\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.554286\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.538876\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.506079\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.534524\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9746/10000 (97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.483840\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.510158\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.539565\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.522798\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.570652\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.546647\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.505262\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.542948\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.512798\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.521001\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.511841\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.539569\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.522107\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.509179\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.484836\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.512219\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.559211\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.502197\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.486075\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.530643\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.530048\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.563081\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.495036\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.526926\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.563061\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.524922\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.515553\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.520759\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.487127\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.554371\n",
      "\n",
      "Test set: Average loss: 0.0149, Acuracy 9752/10000 (98%\n",
      ")\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.570014\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.493752\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.509420\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.529340\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.493041\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.524850\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.516303\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.523551\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.547744\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.475793\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.562501\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.500326\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.500568\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.537196\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.504270\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.542018\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.541572\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.492072\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.528027\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.510181\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.523475\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.545244\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.531162\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.523617\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.552878\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.517140\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.491756\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.516250\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.552953\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.535988\n",
      "\n",
      "Test set: Average loss: 0.0148, Acuracy 9770/10000 (98%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9j/p045mwns5lb5bvtrs9y0wsmr0000gn/T/ipykernel_86641/3258896293.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[3]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim = 1, keepdim = True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
